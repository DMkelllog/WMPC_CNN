{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFE 비교\n",
    "LR SVM RF GBM FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T08:13:36.988618Z",
     "start_time": "2021-02-26T08:13:33.824119Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T08:13:37.005602Z",
     "start_time": "2021-02-26T08:13:37.002581Z"
    }
   },
   "outputs": [],
   "source": [
    "DIM = 64\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCH = 1000\n",
    "TRAIN_SIZE_LIST = [500, 5000, 50000, 162946]\n",
    "lr = 1e-4\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T08:13:41.509310Z",
     "start_time": "2021-02-26T08:13:37.035493Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/X_CNN_64.pickle', 'rb') as f:\n",
    "    X_resize = pickle.load(f)\n",
    "with open('../data/y.pickle', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T08:13:54.987263Z",
     "start_time": "2021-02-26T08:13:41.538273Z"
    }
   },
   "outputs": [],
   "source": [
    "X_resize = (X_resize - 0.5) * 2\n",
    "X_resize_stacked = np.repeat(X_resize, 3, -1)\n",
    "y_onehot = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T08:21:31.839167Z",
     "start_time": "2021-02-26T08:17:08.791987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id: 0 train size: 500 rep_id: 0 macro: 0.4158 micro: 0.9119\n",
      "model_id: 0 train size: 500 rep_id: 1 macro: 0.5009 micro: 0.9332\n",
      "model_id: 0 train size: 500 rep_id: 2 macro: 0.433 micro: 0.9276\n",
      "model_id: 0 train size: 500 rep_id: 3 macro: 0.4581 micro: 0.931\n",
      "model_id: 0 train size: 500 rep_id: 4 macro: 0.4556 micro: 0.9239\n",
      "model_id: 0 train size: 500 rep_id: 5 macro: 0.4266 micro: 0.8884\n",
      "model_id: 0 train size: 500 rep_id: 6 macro: 0.3925 micro: 0.911\n",
      "model_id: 0 train size: 500 rep_id: 7 macro: 0.4107 micro: 0.9251\n",
      "model_id: 0 train size: 500 rep_id: 8 macro: 0.4227 micro: 0.9155\n",
      "model_id: 0 train size: 500 rep_id: 9 macro: 0.4096 micro: 0.9299\n"
     ]
    }
   ],
   "source": [
    "for REP_ID in range(10):\n",
    "    RAN_NUM = 27407 + REP_ID\n",
    "    \n",
    "    for TRAIN_SIZE_ID in range(4):\n",
    "        TRAIN_SIZE = TRAIN_SIZE_LIST[TRAIN_SIZE_ID]\n",
    "        \n",
    "        for MODEL_ID in range(3):\n",
    "            #Model ID = 0: VGG, 1: ResNEt, 2: DenseNet\n",
    "            X_trnval, X_tst, y_trnval, y_tst =  train_test_split(X_resize_stacked, y_onehot, \n",
    "                                                                 test_size=10000, random_state=RAN_NUM)\n",
    "            \n",
    "            # Randomly sample train set for evaluation at various training set size\n",
    "            if TRAIN_SIZE == X_trnval.shape[0]:\n",
    "                pass\n",
    "            else:\n",
    "                X_trnval,_ , y_trnval, _ = train_test_split(X_trnval, y_trnval, \n",
    "                                                            train_size=TRAIN_SIZE, random_state=RAN_NUM)\n",
    "            # Get unique labels in training set. Some labels might not appear in small training set.\n",
    "            labels = np.unique(np.argmax(y_trnval, 1))\n",
    "            \n",
    "            if MODEL_ID == 0: base_model = VGG16(weights=None, pooling='avg', include_top=False)\n",
    "            elif MODEL_ID == 1: base_model = ResNet50V2(weights=None, pooling='avg', include_top=False)\n",
    "            elif MODEL_ID == 2: base_model = DenseNet121(weights=None, pooling='avg', include_top=False)\n",
    "            predictions = tf.keras.layers.Dense(9, activation='softmax')(base_model.output)\n",
    "            model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "            for layer in base_model.layers: layer.trainable = True\n",
    "            model.compile(optimizer= tf.keras.optimizers.Adam(lr=1e-4), \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            log = model.fit(X_trnval, y_trnval, validation_split=0.2, \n",
    "                            batch_size=BATCH_SIZE, epochs=MAX_EPOCH, \n",
    "                            callbacks=[early_stopping], verbose=0)\n",
    "            y_trnval_hat= model.predict(X_trnval)\n",
    "            y_tst_hat= model.predict(X_tst)\n",
    "\n",
    "            macro = f1_score(np.argmax(y_tst, 1), np.argmax(y_tst_hat, 1), labels=labels, average='macro')\n",
    "            micro = f1_score(np.argmax(y_tst, 1), np.argmax(y_tst_hat, 1), labels=labels, average='micro')\n",
    "            cm = confusion_matrix(np.argmax(y_tst, 1), np.argmax(y_tst_hat, 1))\n",
    "\n",
    "            filename = '../result/CNN/WMPC_'+'CNN_'+str(MODEL_ID)+'_'+str(TRAIN_SIZE)+'_'+str(REP_ID)+'_'\n",
    "\n",
    "            with open(filename+'softmax.pickle', 'wb') as f:\n",
    "                pickle.dump([y_trnval_hat, y_tst_hat], f)\n",
    "            with open(filename+'f1_score.pickle', 'wb') as f:\n",
    "                pickle.dump([macro, micro, cm], f)\n",
    "\n",
    "            print('model_id:', MODEL_ID,\n",
    "                  'train size:', TRAIN_SIZE,\n",
    "                  'rep_id:', REP_ID,\n",
    "                  'macro:', np.round(macro, 4), \n",
    "                  'micro:', np.round(micro, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
